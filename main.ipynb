{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "4d0b2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import Environment\n",
    "from magiccube import Cube\n",
    "from agents import A2C, DQN, PPO\n",
    "import yaml\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "50e3522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = yaml.safe_load(open(\"config.yaml\", \"r\"))\n",
    "\n",
    "env = Environment(\n",
    "    method=\"LBL\",\n",
    "    size=3,\n",
    "    args=args[\"environment\"]\n",
    ")\n",
    "\n",
    "agent = DQN(env, args[\"DQN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "fa9012fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          W  W  W                   \n",
      "          W  W  W                   \n",
      "          W  W  W                   \n",
      " O  O  O  G  G  G  R  R  R  B  B  B \n",
      " O  O  O  G  G  G  R  R  R  B  B  B \n",
      " O  O  O  G  G  G  R  R  R  B  B  B \n",
      "          Y  Y  Y                   \n",
      "          Y  Y  Y                   \n",
      "          Y  Y  Y                   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cube = Cube()\n",
    "print(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "ebd13aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  4  3  0 17]\n",
      "  [ 5  0 -1  1 22]\n",
      "  [ 3  0  5  2 19]\n",
      "  [ 5 -1  3  3 11]\n",
      "  [ 1 -1 -1  4  4]\n",
      "  [ 1 -1  4  5  3]\n",
      "  [ 1  5  2  6  8]\n",
      "  [ 2  0 -1  7 24]\n",
      "  [ 4  2  1  8  6]\n",
      "  [-1  4  3  9  9]\n",
      "  [-1  3 -1 10 10]\n",
      "  [-1  5  1 11  5]\n",
      "  [-1 -1  4 12 12]\n",
      "  [-1 -1  5 13 13]\n",
      "  [-1  0  4 14 20]\n",
      "  [-1  2 -1 15 15]\n",
      "  [-1  1  3 16  1]\n",
      "  [ 2  5  0 17 25]\n",
      "  [ 0  3 -1 18 18]\n",
      "  [ 0  2  4 19 23]\n",
      "  [ 2 -1  5 20 16]\n",
      "  [ 0 -1 -1 21 21]\n",
      "  [ 1 -1  2 22  7]\n",
      "  [ 3  4  1 23  0]\n",
      "  [ 4  2 -1 24 14]\n",
      "  [ 5  1  3 25  2]]]\n",
      "(1, 26, 5)\n"
     ]
    }
   ],
   "source": [
    "env.scramble()\n",
    "print(env.state2)\n",
    "print(env.state2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573fdf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "\n",
    "embedding = nn.Linear(5, hidden_size)\n",
    "\n",
    "attention = nn.MultiheadAttention(\n",
    "    embed_dim=hidden_size,\n",
    "    num_heads=4,\n",
    "    batch_first=True\n",
    ")\n",
    "\n",
    "layer_norm = nn.LayerNorm(hidden_size)\n",
    "\n",
    "ffn = nn.Sequential(\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(inplace=True)\n",
    ")\n",
    "\n",
    "output_layer = nn.Sequential(\n",
    "    nn.Linear(hidden_size * 26, hidden_size * 2),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(hidden_size * 2, 12)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "id": "c454da61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0094,  0.0012, -0.1942, -0.1318,  0.1543,  0.3571, -0.2437,  0.1882,\n",
       "         -0.1059, -0.2836, -0.3673, -0.0944]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_tensor = torch.from_numpy(env.state2).float()\n",
    "embedded = embedding(state_tensor)\n",
    "attn_output, _ = attention(embedded, embedded, embedded)\n",
    "attn_output = layer_norm(embedded + attn_output)\n",
    "ffn_output = ffn(attn_output)\n",
    "output = layer_norm(attn_output + ffn_output)\n",
    "\n",
    "flattened = output.view(1, -1)\n",
    "output = output_layer(flattened)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "id": "1227b636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5347,  2.1434,  1.0452,  ..., -0.6848,  0.3639, -0.0204],\n",
      "        [-0.2298,  3.9216,  1.2248,  ..., -1.2748,  1.0381,  0.4056],\n",
      "        [ 0.0752,  5.6998,  1.4044,  ..., -1.8648,  1.7124,  0.8316],\n",
      "        [ 0.3801,  7.4780,  1.5840,  ..., -2.4547,  2.3867,  1.2577]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Output: tensor([[0.8043, 0.2137],\n",
      "        [2.7549, 1.3972],\n",
      "        [4.7054, 2.5807],\n",
      "        [6.6560, 3.7641]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Definiamo un layer lineare: input con 3 feature, output con 2 feature\n",
    "fc1 = nn.Linear(in_features=3, out_features=256)\n",
    "fc2 = nn.Linear(in_features=256, out_features=2)\n",
    "\n",
    "# Esempio di input: batch di 4 esempi, ciascuno con 3 feature\n",
    "input_matrix = torch.tensor([\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0],\n",
    "    [7.0, 8.0, 9.0],\n",
    "    [10.0, 11.0, 12.0]\n",
    "])  # shape: (4, 3)\n",
    "\n",
    "# Passaggio della matrice al layer\n",
    "output = fc1(input_matrix)\n",
    "print(output)\n",
    "output = fc2(output)\n",
    "\n",
    "print(\"Output:\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
